---
title: 'Assignment 4: Predicting Automobile Pricing Using Neural Networks'
author: "Nabeel Khan, Nha Nguyen, Razzaq"
date: "2022-12-02"
output:
  pdf_document: default
  pdf: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
```{r Load, combine and rename datasets}
library(readxl)
library(ISLR)
library(caret)
library(pROC)
library(ROSE)
library(robustbase)
library(smotefamily)
library(ROCR)
library(rpart)
library(rpart.plot)
library(ggplot2)
library(neuralnet)
library(GGally)
library(corrr)
library(tidyverse)
library(ROSE)

#importing the dataset
Assi4 <- read_excel("Assi4.xlsx")
#Summary of the data present in Assi4
summary(Assi4)
# Check missing values
sapply(Assi4,function(x) sum(is.na(x))) #There are no missing values in all columns.
# Factor categorical variables
Assi4$Colour <- as.factor(Assi4$Colour)
#Attach Assi4 to data1
data1 <- Assi4
# Calculate correlation coefficient. #Factors that influence a customer's decision
#to buy a car are Horsepower (HP), Cylinder voloume in cubic cms (CC) and Weight (Wght) 
#whose correlation with car price are 0.923, 0.890 and 0.856 accordingly.

correlate(data1)
# Test relationship between categorical and numerical variables using Chi-squared test
chisq.test(data1$Price, data1$Colour)

```

(1) After your EDA, what factors do you think influence a customer’s decision to buy a car? What are the objectives of the model that Farid plans to build?

Question 1 Answer

There are some variables present in the excel sheet where the variables take the same value for all the observations. These variables were removed from the excel sheet as they do not make any difference to our models as they have the same value for all observations. These varaibles are - Fuel: (Fuel type (Petrol, Diesel, CNG)), Drs(Number of doors), Cyl(Number of cylinders), ABS(Anti-lock brake system (Yes=1, No=0)), Abag1(Driver airbag (Yes=1, No=0)), PStr(Power steering (Yes=1, No=0)). 

The factors that influence a customer’s decision to buy a car are Horsepower (HP), Cylinder (CC), number of gear positions (Grs), Weight (Wght), Air Conditioning (AC) , Metallic Rim "M_rim" since their correlations with Price (target variable) are greater than 0.60, which refer to strong correlation. Their correlation coefficients are 0.92, 0.88, 0.76, 0.86, 0.62, 0.63 accordingly.

Although some variables are more correlate than other to price, we have decided to use all the variables except for the ones removed in the first paragraph

We have then performed normalization to the data after importing it bringing it to a scale between 0 and 1. This makes it easier for neural network model.

Objectives of the model that farid plans to build: For predicting the prices, Farid decided that he would try various machine-learning methods, including linear regression. He also knew that neural networks excelled in predicting price, so he decided to use a feed-forward neural network to train data and accurately predict the price. He wondered how neural networks would compare to linear regression. For long-term marketing, he wanted to decide on one particular computing system to determine prices. 

``` {r Question 2}
# (2) Construct a neural network model. Validate and interpret the model 
# using a different number of hidden neurons.

#Create a function to normalize data between 0 and 1
mynormalization <- function(x)
{
  (x - min(x))/ (max(x)-min(x))
}
#Apply normalization to only those coloumns that are numerical
data1 <- Assi4%>% mutate_if(is.numeric, mynormalization)
summary(data1)


#Create training and test data
set.seed(124)
indx <- sample(2, nrow(data1), replace = T, prob = c(0.7, 0.3))
train <- data1[indx == 1, ]
test <- data1[indx == 2, ]

#Create Neural Network Model
set.seed(12321)
nnModel1 <- neuralnet(Price ~ Age + KM + HP + MC + Auto + CC + Grs + Wght + G_P + Mfr_G + Abag_2 + 
                        AC + Comp + CD + Clock + Pw + Radio + SpM + M_Rim + Tow_Bar, data = train,
                      err.fct = 'sse', hidden = c(3,2), threshold = 0.01, linear.output = T)


#Check for error and other parameters using result.matrix
nnModel1$result.matrix
#Error on training set for this model is 0.011562574
#Plot the model
plot(nnModel1, rep = 'best')

# Predict on test data
pr.nn <- neuralnet::compute(nnModel1, test[,1:22])

# Compute mean squared error
pr.nn_ <- pr.nn$net.result * (max(data1$Price) - min(data1$Price)) + min(data1$Price)
pr.nn_
test.r <- (test$Price) * (max(data1$Price) - min(data1$Price)) +
  min(data1$Price)
test.r
#MSE.nn is the Mean Squared Error on the test data
MSE.nn <- sum((test.r - pr.nn_)^2) / nrow(test)
MSE.nn
#MSE.nn is the mean squared error for test data which is 0.01830637 

# Plot regression line
plot(test$Price, pr.nn_, col = "red",
     main = 'Real vs Predicted')
abline(0, 1, lwd = 2)

```
I have used various hidden neurons like (5,4,2), (4,2), (2,1) and (3,2) and have finally decided to use (3,2) after comparing the error for each on training and test data. For the Real vs pred graph, we can see that the predictions (red circles) made by the neural network are in general concentrated around the line (a perfect alignment with the line would indicate an MSE of 0 and thus an ideal prediction).
``` {r Question 3} 
# (3) Compare your neural network models with linear regression model. Which one is better?

# Converting "Price" as numeric and factorize "Colour" variable
data1$Price <- as.numeric(data1$Price)
data1$Colour <- as.factor(data1$Colour)

# Split train test and test set for lm regression
set.seed(123)
lm.indx <- sample(2,nrow(data1), replace = T, prob = c(0.7,0.3))
lm.train <- data1[lm.indx == 1,]
lm.test <- data1[lm.indx ==2,]

full <- lm(lm.train$Price ~ .,data = lm.train)
null <- lm(lm.train$Price ~ 1,data = lm.train)

step(null, scope = list(lower = null, upper = full), direction = "forward", trace = 0)

#Create LM Model
#I have taken -Tow_Bar - Radio -Pw -Comp -Abag_2 -G_P -Colour variables out as when 
#we split it into train and test data, that is because the datasets were imbalanced 
#and linear regression failed. You might think this is wrong to remove variables like 
#this but I can justify it as they did not have a high correlation with 'price' when 
#we ended up doing EDA in question 1. Hence it is justified.

lmModel <- lm(formula = lm.train$Price ~. -Tow_Bar - Radio -Pw -Comp -Abag_2 
              -G_P -Colour, data = lm.train)
summary(lmModel)

# LR prediction on train data and test data
train_MSE = mean(lmModel$residuals^2)
test_MSE = mean((lm.test$Price - predict.lm(lmModel, lm.test)) ^ 2)
train_MSE #0.001999398
test_MSE  #0.01692538

fitted(lmModel)
coefficients(lmModel)
residuals((lmModel))
plot(lmModel)


```
As we can see, I have got error MSE on train and test data of linear regression model in this question and also neural network model in the previous question. It is clearly seen that error is less for linear regression model when compared to neural network model but it is noteworthy to keep in mind that we considered all the variables for our neural network model. Also, the training and test error for neural network model were almost similar whereas for LM model we can clearly see that training set has very less error when compared to test error. This can mean that our LM model can be slightly overfitted. As to which one is better, I would say it depends on the individual deciding as we can prune both models to satisfy our needs with the question but I personally would go for the neural network model as it would lead to more accurate and faster results when we are working with huge and changing datasets.

Question 4
(4)Make a decision and offer your recommendations.
Decision: Neural network is a better model 
Recommendations: The dataset used for this exercise is very small when compared to actual practical datasets for car prices. For practical use, neural network is the better model as it takes into account all the variables and can easily change accordingly if our needs from the model change in the future. I would still like to point out that as we are getting lower error for LM model, it would not be fair to completely neglect that option.

```